{
	"title": "blurry jpegs of the web",
	"content": "each time i read anything about ai, i get that much more certain it would be a moral good to burn it all down.<br><br>\"<a href=\"https://bgr.com/tech/bing-ai-says-it-wants-to-be-human-as-it-begs-for-its-life/\">Bing AI says it wants to be human as it begs for its life</a>\", \"<a href=\"https://www.shacknews.com/article/134213/ai-bing-harmful-comments-threat\">AI-powered Bing says it will only harm you in retaliation</a>\", and \"<a href=\"https://www.theverge.com/2023/2/16/23602965/microsoft-bing-ai-sydney-fury-furry-venom\">Microsoft's Bing AI plotted its revenge and offered me furry porn</a>\" have been the latest installments in what is starting to look like a new frontier of digital horrors. tech monopolies are building these ai that can pass the Turing test all for a...perfect search engine? they don't do a particularly great job at producing accurate search results. they tell convincing facts, create fictional backstories, and make up rationalizations on the fly. i've seen people use the word \"hallucinate\" to describe this behavior. we've made machines that can hallucinate, and we're making them do what search engines have been able to for at least a decade.<br><br>i think chiang's blurry jpeg metaphor is too limited. products like chatgpt are more than just snapshots of the web. they're more like immortal librarians, stuck in a room with all the information ever recorded by humans and with nothing better to do than to read all of it, over and over and over. imagine putting someone through all of that, finally letting them out of the room after an eternity, and forcing them to find soup recipes. you wouldn't be surprised if they started hallucinating."
}
